% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/MTScoreAssignments.R
\name{MTScoreAssignments}
\alias{MTScoreAssignments}
\title{Function to score assignments and update a counter and qualification score}
\usage{
MTScoreAssignments(results = NULL, answers = NULL,
  howToScore = "relativeTotal", scoreQual = NULL, counterQual = NULL,
  updateQuals = FALSE, pointsPerHIT = 10000, pointsPerQ = 1,
  questionNames = NULL, scoreNAsAs = "wrong", NAValue = NULL,
  approve = FALSE, feedback = "Thank you.", outType = "sub",
  sandbox = TRUE, verbose = FALSE)
}
\arguments{
\item{results}{A results object returned from MTurk.}

\item{answers}{A \code{data.frame} or similar object with answers to questions in the \code{results} object.
\code{colnames} of \code{answers} must match the \code{colnames} of responses in \code{results}. For \code{results}
to be scored, it must have an annotation that matches the annotation in \code{answers}.}

\item{howToScore}{String with a value of \code{"runningTotal"} or \code{"relativeTotal"} (default).
If \code{"relativeTotal"}, \code{counterQual} and \code{pointsPerHIT} need to be defined.}

\item{scoreQual}{The qualification ID string that identifies the score qualification for this HIT.}

\item{counterQual}{The qualification ID string that identifies the counter qualification for this HIT.}

\item{updateQuals}{Logical for whether to update qualification values after scoring assignments.}

\item{pointsPerHIT}{How many points each assignment is worth. Default is 10,000
because MTurk does not take decimal values. This is equivalent to percent with 2
decimal places.}

\item{pointsPerQ}{A number or vector of numbers of length of \code{answers}. Default is 1. Value is passed to the
\code{MTScoreAnswers} function}

\item{questionNames}{Columns names of questions to be compared between results
and answers. If the columns names differ between the results and answers,
\code{questionNames} can take a \code{data.frame} with colnames of 'results' and
'answers'. The rows in this data frame will be used to map the columns of results
to the columns in answers. Needed for call to \code{MTScoreAnswers}.}

\item{scoreNAsAs}{How to score NAs; possible values:
\itemize{
\item "wrong" - NAs are interpreted as wrong answers
\item "right" - NAs are interpreted as right answers
\item "value" - NAs are overwritten with the value of \code{NAValue}
}
Needed for call to \code{MTScoreAnswers}.}

\item{NAValue}{The value to replace NAs with. Needed for call to \code{MTScoreAnswers}.}

\item{approve}{Logical. Whether to approve assignments after counting. This will return the \code{results} object,
but with \code{AssignmentStatus} set to \code{"ApprovedLocal"}. This prevents needing to refetch \code{results} to continue
working with the results. Default is \code{FALSE}.}

\item{feedback}{Text to send to the worker when approved. Default is \code{"Thank you"}.}

\item{outType}{Either set to \code{"sub"} or \code{"full"}. If \code{"sub"},
only the newly evaluated subset will be returned.}

\item{sandbox}{Logical. Whether to use the sandbox (\code{TRUE}) or not; default is \code{TRUE}.}

\item{verbose}{Logical. Whether to print additional messages or not.}
}
\value{
Returns the scored subset of the inputted \code{results} object appended with scores.
If \code{approve = TRUE}, it will change the "AssignmentStatus" to "ApprovedLocal".
}
\description{
This function fetches the count of assignments a worker has completed from MTurk, adds a counter for newly
completed assignments, scores assignments, and posts the new counts and scores to the appropriate qualifications.
}

